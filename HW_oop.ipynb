{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from lxml.etree import tostring\n",
    "import time\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "#nltk.download('popular', halt_on_error=False)\n",
    "\n",
    "import nltk\n",
    "#textblob\n",
    "\n",
    "from textblob import TextBlob, Word\n",
    "import numpy as np #for numeric operations\n",
    "import pandas as pd #for dealing with dataframes\n",
    "import matplotlib.pyplot as plt #for visualization\n",
    "import re\n",
    "import time\n",
    "from lxml.cssselect import CSSSelector\n",
    "from lxml import html\n",
    "import json\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from glob import glob\n",
    "from collections import Iterable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a utils.py file which will have the following classes/functions defined:\n",
    "#. 1.5 points Scrape_All class, which will scrape from a given page all:\n",
    "a. hyperlinks  and provide the absolute link if relative one is given in the page,\n",
    "b. headings and paragraphs and merge them inside one string with a new line between different headings/paragraphs, without distorting order).\n",
    "c. custom tags provided by the user i.e. if the user provides li.author or similar input then all the list items that have class author must be scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scrape_All:\n",
    "    \"\"\"This class helps get data using different methods B4 xpath and selenium\"\"\"\n",
    "    def __init__(self,url):\n",
    "        self.url=url\n",
    "        self.response=requests.get(self.url)\n",
    "        self.page=self.response.content\n",
    "    def beaut(self):\n",
    "        pageB=BeautifulSoup(self.page, \"html.parser\")\n",
    "        self.pageB=pageB #beautiful page\n",
    "        return pageB\n",
    "    def s_lxml(self):\n",
    "        tree = html.document_fromstring(self.page)\n",
    "        self.tree=tree #xpath treee\n",
    "        return tree\n",
    "    def selen(self):\n",
    "        browser = webdriver.Chrome()\n",
    "        browser.get(self.url)\n",
    "        time.sleep(3)\n",
    "        elems = browser.find_elements_by_xpath(\"//a[@href]\")\n",
    "        ablinks=[i.get_attribute(\"href\") for i in elems]\n",
    "        self.selen_links=ablinks #hyperlinks this one by default get the whole links\n",
    "        return browser #browser \n",
    "    def hyperlinks(self,base=\"\"):#I did not specify the base because in some cases it cannot be equal to url\n",
    "        try:\n",
    "            links=[i.get(\"href\") for i in self.pageB.find_all(\"a\")]\n",
    "            ablinks=[str(base)+ str(i) for i in links]\n",
    "            return ablinks\n",
    "        except:\n",
    "            links=self.tree.xpath(\"//a/@href\")\n",
    "            ablinks=[str(base)+ str(i) for i in links]\n",
    "            return ablinks\n",
    "    @property\n",
    "    def get_text_content(self):\n",
    "        text=\"\"\n",
    "        for header in self.pageB.find_all(re.compile(\"h[1-6]{1}\")):\n",
    "            text+=header.get_text() + u'\\n'\n",
    "            for elem in header.next_siblings:\n",
    "                if elem.name and elem.name.startswith('h'):\n",
    "                    # stop at next header\n",
    "                    break\n",
    "                if elem.name == 'p':\n",
    "                    text+=elem.get_text() + u'\\n'\n",
    "        return text\n",
    "    def get_tag(self):\n",
    "        tag=input(\"input a tag \")\n",
    "        attribute_type =input(\"enter selector type: class, id, etc \")\n",
    "        attribute_name=input(\"enter selector name \") \n",
    "        try:\n",
    "            return self.pageB.find_all(tag, attrs={attribute_type:attribute_name})\n",
    "        except:\n",
    "            return self.tree.xpath(\"//%s[@%s='%s']\"%(tag,attribute_type,attribute_name))\n",
    "    \n",
    "       \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super_list class, which will take a list as input and provide the following functionalities:\n",
    "a. untilst function, that will return the unlisted version of a nested list or the same one if list was not nested,\n",
    "b. merge function, that will merge all the elements of any list into strings,\n",
    "c. find function that will take a type argument as an input. If type =:\n",
    "i. number, then it will return all the list elements that include a number,\n",
    "ii. letter, then it will return all the list elements that include a letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Super_list:\n",
    "   \n",
    "    def __init__(self,ls):\n",
    "        self.ls=ls\n",
    "    #def unlist(self):\n",
    "    #    if any(isinstance(i, list) for i in self.ls)==True:\n",
    "    #       return list(chain.from_iterable(self.ls))\n",
    "    #   else:\n",
    "    #        return self.ls\n",
    "    def unlist(self):\n",
    "        \"\"\"the method defined above will not unlist mixed lists like [123,[\"123\",[23]],\"vazgen\"] which contain integers \n",
    "        and mixed lists so this one can handle problems like that\"\"\"\n",
    "        new_list=[]\n",
    "        for i in range(len(self.ls)):\n",
    "            inp = self.ls[i]\n",
    "            if inp.__class__ == list:\n",
    "                contains_list = any(map(lambda x: x.__class__ == list, inp))\n",
    "                if contains_list:\n",
    "                    unlist(inp, new_list)\n",
    "                else:\n",
    "                    new_list.extend(inp)\n",
    "            else:\n",
    "                new_list.append(inp)\n",
    "        return new_list\n",
    "    def to_string(self):\n",
    "        new=[str(i) for i in self.unlist()] #made it str because we might have integers inside list\n",
    "        return \" \".join(new)\n",
    "    def typelem(self,tip=str):\n",
    "        new=[i for i in self.ls if isinstance(i, tip)]\n",
    "        return new\n",
    "    def select(self):\n",
    "        choice=input(\"what do you want to get? \").lower()\n",
    "        if choice==\"numbers\":\n",
    "            return [float(i) for i in self.unlist() if str(i).isdigit()==True]\n",
    "        elif choice==\"letters\":\n",
    "            return [str(i) for i in self.unlist() if str(i).isalpha()==True]\n",
    "        else:\n",
    "            print(\"please insert numbers or letters\")\n",
    "            return self.select()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaner class, which will take a string as an input and provide the following methods:\n",
    "a. tokenize into words/sentences,\n",
    "b. lemmatize, clean stopwords,\n",
    "c. make plural/singular,\n",
    "d. uppercase/lowercase,\n",
    "e. draw frequency distributions of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cleaner:\n",
    "    def __init__(self,string):\n",
    "        self.string=TextBlob(string)\n",
    "        self.words=self.string.words\n",
    "        self.sentences=self.string.sentences\n",
    "    \n",
    "    \"\"\" This method works but i prefered do it as an attribute\n",
    "    def tokenize(self,get_words=True,get_sent=False):\n",
    "        if get_words==True and get_sent==False:\n",
    "            words=self.string.words\n",
    "            return words\n",
    "        elif get_sent==True and get_words==False:\n",
    "            sent=self.string.sentences\n",
    "            return sent\n",
    "        else:\n",
    "            words=self.string.words\n",
    "            sent=self.string.sentences\n",
    "            return words,sent\"\"\"\n",
    "    def lem_stopwords(self,lang=\"english\"):\n",
    "        sw = stopwords.words(lang)\n",
    "        new = [i for i in self.words if i not in sw and len(i)>2]\n",
    "        cleaned=TextBlob(\" \".join(new))\n",
    "        a=[]\n",
    "        ## here we will loop twice to lemmatize both verbs and nouns\n",
    "        for i in cleaned.words:\n",
    "            a.append(i.lemmatize(\"v\"))\n",
    "        c=TextBlob(\" \".join(a)).words\n",
    "        d=[]\n",
    "        for i in c:\n",
    "            d.append(i.lemmatize(\"n\"))\n",
    "        las=TextBlob(\" \".join(d)).words\n",
    "        return TextBlob(\" \".join(las))\n",
    "    def plur_sing(self,plur=True):\n",
    "        if plur==True:\n",
    "            return self.lem_stopwords().words.pluralize()\n",
    "        else:\n",
    "            return self.lem_stopwords().words.singularize()\n",
    "    def upper_lower(self,upper=True):\n",
    "        if upper==True:\n",
    "            return self.words.upper()\n",
    "        else:\n",
    "            return self.words.lower()\n",
    "    def freq(self,n=10):\n",
    "        freq = nltk.FreqDist(Cleaner(\" \".join(self.upper_lower(False))).lem_stopwords().split(\" \"))\n",
    "        return freq.plot(10,cumulative=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
